{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgXZjbVMN89s"
   },
   "source": [
    "# Fundamentals of Computer Science\n",
    "\n",
    "## Lecture 11: Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWu-EXaOq2Bi"
   },
   "source": [
    "We start off very simply by loading a dataset from scikit-learn. In this case we are loading the [20 newsgroups dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html?highlight=newsgroups#sklearn.datasets.fetch_20newsgroups).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3Tsyx_agDEm",
    "outputId": "ddf397a0-9617-42e4-f28b-daef66539fc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: bbs.mirage@tsoft.net (Jerry Lee)\n",
      "Subject: Cobra 2.0 1-b-1 Video card HELP ME!!!!\n",
      "Organization: The TSoft BBS and Public Access Unix, +1 415 969 8238\n",
      "Lines: 22\n",
      "\n",
      "Does ANYONE out there in Net-land have any information on the Cobra 2.20 \n",
      "card?  The sticker on the end of the card reads\n",
      "        Model: Cobra 1-B-1\n",
      "        Bios:  Cobra v2.20\n",
      "\n",
      "I Havn't been able to find anything about it from anyone!  If you have \n",
      "any information on how to get a hold of the company which produces the \n",
      "card or know where any drivers are for it, PLEASE let me know!\n",
      "\n",
      "As far as I can tell, it's a CGA card that is taking up 2 of my 16-bit \n",
      "ISA slots but when I enable the test patterns, it displays much more than \n",
      "the usualy 4 CGA colors... At least 16 from what I can count.. Thanks!\n",
      "\n",
      "              .------------------------------------------.\n",
      "              : Internet: jele@eis.calstate.edu          :\n",
      "              :           bbs.mirage@gilligan.tsoft.net  :\n",
      "              :           bbs.mirage@tsoft.sf-bay.org    :\n",
      "              :           mirage@thetech.com             :\n",
      "              : UUCP    : apple.com!tsoft!bbs.mirage     :\n",
      "              `------------------------------------------'\n",
      " \n",
      "                    Computer and Video Imaging Major\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=[\"comp.graphics\"], shuffle=True, random_state=42)\n",
    "print(twenty_train.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwH9YBZquSgQ"
   },
   "source": [
    "There is a \"problem\": The class labels are actually `int`s. We can \"restore\" the original string labels to make them human-readable again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhfDtnaXgfSw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(twenty_train.data, columns=[\"text\"])\n",
    "# targets = [twenty_train.target_names[x] for x in twenty_train.target]\n",
    "targets = twenty_train.target\n",
    "train_df['target'] = pd.Series(data=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Sh6ZRFSTukEd",
    "outputId": "308478f2-07f5-4cc2-d5c0-9bae2a288148"
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xs6yuLK7veNZ"
   },
   "source": [
    "We need **features** to train our classifier with. One simple way to extract features from text data is to create a **bag-of-words** model. It simply counts how often each word appears in a text.\n",
    "\n",
    "This means we ignore the grammar completely! In practice however this approach works reasonably well for text classification though better and more sophisticated approaches exist. It is nevertheless a good starting point when you first start doing machine learning tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Noe5mOS_gxzo",
    "outputId": "e0654734-5c6a-4e4c-d323-1401f8001221"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "lst = [\"Hello\", \"World\", \"Goodbye\", \"World\"]\n",
    "c = Counter(lst)\n",
    "print(c)\n",
    "print(c[\"Does not exist\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "122yYHoTwmK2"
   },
   "source": [
    "Here we use the `CountVectorizer` to do this process for us. It takes all the texts, \"learns\" which words exist and creates a *sparse* matrix where each row is a document and each column is a word, and the values in the cells are the word frequency of that word for that particular text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHnqjxuWg00g",
    "outputId": "2c8513cb-e3df-40f3-f79c-0c2e06da3925"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_df[\"text\"])\n",
    "print(X_train.shape)\n",
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNto_sA4wkOS",
    "outputId": "d7302262-cd86-4419-e1dd-ee2d25449f6e"
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGnls-swN89w"
   },
   "source": [
    "tf-idf stands for *term frequency — inverse document frequency*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4v16lvaJN89x"
   },
   "source": [
    "Now let's look at what is happening a bit more in-depth. Here, we have 4 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Qi0fvbRN89x",
    "outputId": "43a7ccfa-d892-4a1e-8706-fc1fbfac3a39"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data_set = (\n",
    "    \"Bali is an island and not a country\",\n",
    "    \"Peru is a country in south america\",\n",
    "    \"This is a country. That is not a country\",\n",
    "    \"japan is a country made of more than one island\"\n",
    ")\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "vectorizer.fit(data_set)\n",
    "\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBn4dVV-N89z",
    "outputId": "15d6c494-7b20-43eb-e15b-06919c4eeea7"
   },
   "outputs": [],
   "source": [
    "# Converting dataset into spare matrix\n",
    "smatrix = vectorizer.transform(data_set)\n",
    "\n",
    "print(smatrix)\n",
    "print(smatrix.shape)\n",
    "# Note that the sparse matrix created called smatrix is a scipy sparse matrix with\n",
    "# elements stored in coordinate format. But you can convert it into a dense format.\n",
    "# Dense representation of the above sparse matrix\n",
    "\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "smatrix.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee2pKryWN890"
   },
   "source": [
    "Each row in the output matrix corresponds to document in the data_set. Each column corresponds to corresponding words from the vocabulary. \n",
    "For example: column 0 is for ‘america’. column 1 is for ‘bali’ and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1OZSCJ8N890"
   },
   "source": [
    "Each element of the matrix is ‘term frequency’, i.e. number of times the word appears in that particular document.\n",
    "For Example: ‘country’ appears 2 times in document 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmlcCxoDN891"
   },
   "source": [
    "Finally, idf (inverse document frequency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KB9TvYyRN891"
   },
   "source": [
    "$$ idf_t = \\log \\frac{1+N}{1+df_t}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ER6bt54BN892"
   },
   "source": [
    "$N$ cardinality of our document space. In this example it is `4`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPmPF8QnN892"
   },
   "source": [
    "$df_t$ the number of documents that term t appears in **(adding 1 into the formula to avoid zero-division)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70oqiTDxN892",
    "outputId": "7f83ca68-b7b7-44f4-fd58-7314475c3f64"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer() #by default norm = \"l2\"\n",
    "\n",
    "tfidf.fit(smatrix)\n",
    "\n",
    "print(\"IDF:\", tfidf.idf_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZInJ1TDDN893"
   },
   "source": [
    "IDF is calculated for each feature (in this case each term t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYbTON1gN893"
   },
   "source": [
    "idf for term 'island':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6R6wIV9N893"
   },
   "source": [
    "\\begin{align} \n",
    "N&=4\\\\\n",
    "df_t  =  df(\\text{island}) & = 2 \\qquad \\text{Island appears in document 1 & 4}\\\\\n",
    "idf & =  \\log \\frac{1+4}{1+2}+1\\\\\n",
    "& = log \\frac{5}{3}+1\\\\\n",
    "& = 0.51 + 1\\\\\n",
    "& = 1.51 \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJyM9vGIN894"
   },
   "source": [
    "Using the above IDF, tf-idf is calculated by multiplying it with term frequency matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CL_5G1rwN894"
   },
   "source": [
    "tf-idf calculation of document 1\n",
    "\n",
    "\\begin{align}\n",
    "\\vartheta_{tfidf} & = \n",
    "\\begin{bmatrix}\n",
    " 0 & 1 & 1 & 1 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "\\times\n",
    "\\begin{bmatrix}\n",
    "1.916 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 1.916 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1.916 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1.916 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1.916 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1.916 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 1.916\n",
    "\\end{bmatrix} \\\\\n",
    "\\vartheta_{tfidf} & = \\begin{bmatrix}\n",
    " 0 & 1.916 & 1 & 1.51 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yf9xPZKLN894"
   },
   "source": [
    "Final step is to normalize each row of this matrix. This is to overcome a bias towards frequently repeated words in long documents which might make them look more important than they are just because of the high frequency of the term in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VS31VvHJN895"
   },
   "source": [
    "Please note: `TfidfTransformer` does the above calculation and L2 normalization (by default) on the `smatrix`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIr0cM0JN895"
   },
   "source": [
    "L2 normalization is the most famous method to normalize. Below is an image where L2 norm calculation is worked out on row1 for the above matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etNRbUXzN895"
   },
   "source": [
    "\\begin{align}\n",
    "\\vec{tfidf_{doc1}} & = \\begin{pmatrix} \n",
    "0 & 1.916 & 1 & 1.51 & 0 & 0 & 0 \n",
    "\\end{pmatrix}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQX6Rs3PN895"
   },
   "source": [
    "\\begin{align}\n",
    "\\vartheta_{tfidf}  & = \\begin{bmatrix}\n",
    " 0 & 1.916 & 1 & 1.51 & 0 & 0 & 0\n",
    "\\end{bmatrix} \\quad \\text{without norm} \\\\\n",
    "\\text{Apply L2 norm} \\\\\n",
    "\\vartheta_{norm}  & = \\frac{ \\begin{bmatrix}\n",
    " 0 & 1.916 & 1 & 1.51 & 0 & 0 & 0\n",
    "\\end{bmatrix}}{\\sqrt{1.916^2+1^2+1.52^2}}\n",
    "= \n",
    "\\frac{ \\begin{bmatrix}\n",
    " 0 & 1.916 & 1 & 1.51 & 0 & 0 & 0\n",
    "\\end{bmatrix}}{2.63} \\\\\n",
    "\\vartheta_{norm}  & = \n",
    "\\begin{bmatrix}\n",
    " 0 & 0.726 & 0.379 & 0.572 & 0 & 0 & 0\n",
    "\\end{bmatrix} \\quad \\text{for document 1} \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ve8WDIi2N895"
   },
   "source": [
    "Final matrix after normalization is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7INzq9_rN896",
    "outputId": "f89dffac-9565-403b-adfa-04f726c75b8f"
   },
   "outputs": [],
   "source": [
    "tf_idf_matrix = tfidf.transform(smatrix)\n",
    "\n",
    "print(tf_idf_matrix.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhQpHBvPN896"
   },
   "source": [
    "- Larger the value, more important is the term for that document.\n",
    "- If a particular term say ‘t1’ exists in all the documents, along with some unique terms in a particular document. ‘t1’ is assigned less weightage than the unique terms in that document.\n",
    "For example: in the first document 1 = ‘Bali is an island and not a country’ \n",
    "for tf_idf_matrix we can see row 1 has term ‘country’ assigned less weightage (=0.379) when compared to term ‘bali’ with weightage of 0.726 which exists only in that document. term ‘island’ is given weightage of 0.572 which is between that of ‘bali’ and ‘country’ as it appears in document 4 as well.\n",
    "- tf-idf matrix can be used as a feature set for your logistic regression or decision tree based machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9s9MxGaoN896",
    "outputId": "bd9cb899-94b1-446e-8248-7536827df903"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "print(tfidf.fit_transform(data_set).todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UhwH9tHxOwt"
   },
   "source": [
    "One important step we technically don't **have to** do, but **absolutely should do**, is split our data into a training and a test set. To train our machine learning model we need to give it some data. \n",
    "\n",
    "But then of course we want to know how good our model is. For classification we can give our model some data where we know the class that the model should give us, and compare what the model tells us (the prediction) with the correct solution (that we know, because we ask the model to give us a prediction for data we already know the answer to).\n",
    "\n",
    "We could train our model on the data, and then ask the model to predict the class for the data that it was trained on, but then the model could just \"cheat\" and remember the solution from when it saw this data during training.\n",
    "\n",
    "Instead what we do is to keep some of our data for **testing** and use some of the data for **training**. We train our model on the training data, and then we use the testing data to evaluate the model.\n",
    "\n",
    "We ask the model to predict the output for our testing data. During this process it doesn't see the correct output! The testing data is data the model has never seen before. But we know the correct output, so we can compare the output of the model with the correct output and for example calculate in % how often the model told us the correct output.\n",
    "\n",
    "Then, if we train the model again with different parameters, or if we train a completely different model on the same data, we can compare which of the models is the best one, based on how often they predicted correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rt-UmD8e0MgK"
   },
   "source": [
    "scikit-learn has a very convenient method that helps us split the data into a training and testing set, but of course we could do this by hand too. It's just more convenient to use this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9KXDfB1N896",
    "outputId": "5e76bfcc-572c-47f7-a3d8-bee1f86f9284"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "train_df = pd.DataFrame(twenty_train.data, columns=[\"text\"])\n",
    "targets = [twenty_train.target_names[x] for x in twenty_train.target]\n",
    "train_df['target'] = pd.Series(data=targets)\n",
    "t_train, t_test = train_test_split(train_df,train_size=0.6)\n",
    "print(len(t_train), len(t_test), type(t_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Ofr8x3XyrujR",
    "outputId": "d1479c2d-e657-4808-98b9-c1aa5a675534"
   },
   "outputs": [],
   "source": [
    "t_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chZBaSZO0XDM"
   },
   "source": [
    "Next we will take a look at the [IRIS dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Lw5BKjiFk2If",
    "outputId": "3e6c7168-b710-4620-b773-7fc4eb92fc55"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FzNEin4jk4a7",
    "outputId": "9a2afad4-b5ba-4abd-fe4e-74480b38b0c2"
   },
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(iris.target)\n",
    "labels.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9urEQ0_-k-1L",
    "outputId": "308ce3c4-62c1-4878-d80b-ce372886da66"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :2], labels[0])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUYM1lxj0pVG"
   },
   "source": [
    "Here in this cell is the entire code we need to train a classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_nF1dTzlENY",
    "outputId": "d3c595e1-342d-4d80-a499-9f3b1208765a"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n_neighbors = 3\n",
    "clf = KNeighborsClassifier(n_neighbors)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IP7Zjv-07IH"
   },
   "source": [
    "Of course we want to know how good our model is. Here we calculate the **F1** metric, and we also perform **cross-validation**.\n",
    "\n",
    "More specifically, we perform **k-fold cross-validation** here. We split our data into 10 blocks, and each block is used as a testing set once, all the other blocks are used for training. That means we train and evaluate our model 10 times!\n",
    "\n",
    "Then, for each training run, we get the **F1** score, here macro-averaged. The macro here means that we calculate the F1-score for *each class independently*, and then average. So in total we get 10 F1-scores, one for each training run. This gives us a good indication whether or not our model is actually good. We could have a situation where the data we use for testing is very easy, and so our model gets a very high score, but it fails for every other case. We could notice that if we see that one of the 10 scores is much higher than the rest, and then if we average the 10 scores we have a much better understanding of the quality of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VwMXCvnnlL56",
    "outputId": "62282673-516c-4ce7-89a2-371ce43733a7"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = fetch_20newsgroups(shuffle=True)\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "X_data = vec.fit_transform(X[\"data\"])\n",
    "clf = PassiveAggressiveClassifier()\n",
    "cross_val_score(clf, X_data, X[\"target\"], cv=10, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugihDx2x38An"
   },
   "source": [
    "We have talked about the F1-score, but not how to calculate it. To calculate it we actually need two other metrics, the **Precision** and the **Recall**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzHJ8G8nlm2C"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "X_train = vec.fit_transform(train[\"data\"])\n",
    "clf = PassiveAggressiveClassifier()\n",
    "clf.fit(X_train, train[\"target\"])\n",
    "\n",
    "X_test = vec.transform(test[\"data\"])\n",
    "y_test = test[\"target\"]\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tNMK8uM4PwT"
   },
   "source": [
    "First though we must understand a few key concepts: True Positives (TP), False Positives (FP), False Negatives (FN) and True Negatives (TN).\n",
    "\n",
    "\n",
    "*   TP: An element belongs to a class, and the classifier predicted it as this class.\n",
    "*   FP: An element does **not** belong to a class, but the classifier predicted it as this class.\n",
    "*   FN: An element belongs to a class, but the classifier did **not** predict it as this class.\n",
    "*   TN: An element does **not** belong to a class, and the classifier did **not** predict it as this class.\n",
    "\n",
    "These values are calculated from the \"perspective\" of a class.\n",
    "\n",
    "Let's assume we have to classes, *Fruit* and *Vegetable*.\n",
    "\n",
    "Fruit = Apple, Banana, Pineapple\n",
    "\n",
    "Vegetable: Cucumber, Carrot, Onion\n",
    "\n",
    "We have given our classifier these elements, and it is telling us the following:\n",
    "\n",
    "Fruit* = Apple, Banana, Carrot, Onion\n",
    "\n",
    "Vegetable* = Pineapple, Cucumber\n",
    "\n",
    "\n",
    "How many TPs for Fruit do we have? For this we look at the predictions of our classifier. We count all those elements that are actually Fruits as TPs for the Fruit class: Apple, Banana. So we have 2 TPs for the Fruit class.\n",
    "\n",
    "How many TPs for Vegetable do we have? Only one, Cucumber. Cucumber is a vegetable, and the classifier told us that it is a vegetable.\n",
    "\n",
    "Next, the FPs for Fruit: When did our classifier say something is a Fruit, even though it is not? That happened for Carrot and Onion. So we have 2 FPs for the Fruit class.\n",
    "\n",
    "What about Vegetable? Only one, Pineapple.\n",
    "\n",
    "Next the False Negatives. For Fruit we must look at all elements that **are** Fruits, but that our classifier did not assign the Fruit class to: This happened only for Pineapple, so we have 1 FN for the Fruit class.\n",
    "\n",
    "For Vegetable we have 2! Carrot and Onion are Vegetables, but the classifier did not predict the Vegetable class.\n",
    "\n",
    "The TNs work exactly the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d65kZFEd6LUx"
   },
   "source": [
    "Let's begin with Precision. It tells us how often, when we predicted a class, was the classifier correct.\n",
    "\n",
    "\\begin{align}\n",
    "P = \\frac{TP}{TP+FP}\n",
    "\\end{align}\n",
    "\n",
    "For Fruit, we get a Precision of: $$P_{Fruit} = \\frac{2}{2 + 2} = 0.5$$\n",
    "\n",
    "And for Vegetable: $$P_{Vegetable} = \\frac{1}{1 + 1} = 0.5$$\n",
    "\n",
    "This means that when our classifier predicted the Vegetable (or Fruit) class, it was right half the time, or 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53SOrduX6z_s"
   },
   "source": [
    "Next is the Recall. It tells us how often we have assigned the class out of how often we *should have* assigned the class.\n",
    "\n",
    "$$R = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "For Fruit, we get a Recall of: $$R_{Fruit} = \\frac{2}{2 + 1} = 0.67$$ \n",
    "\n",
    "And for Vegetable: $$R_{Vegetable} = \\frac{1}{1 + 2} = 0.33$$\n",
    "\n",
    "This means that we assigned Fruit class to 67% of the elements that should have, but only did the same for the Vegetable class for 33% of the elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvwGzS6s7uws"
   },
   "source": [
    "The F1-measure then combines these two metrics, to give us a more \"balanced\" score. In reality in some cases we care more about Precision than Recall, but often both are important.\n",
    "\n",
    "$$F1 = 2 * \\frac{P*R}{P+R}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWc0Mtkh-sc8"
   },
   "source": [
    "Then there is another metric, the Accuracy.\n",
    "\n",
    "$$A = \\frac{TP + TN}{TP + FP + FN + FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-IQK5oJ8LYf"
   },
   "source": [
    "Of course we can speed up this process of manual calculations with Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IahteeHnl9_M",
    "outputId": "fb7373cc-046f-4ba7-b527-3da8c0fd365f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeOHaZrd8Q0r"
   },
   "source": [
    "It's also useful to see where the classifier is going wrong specifically.\n",
    "\n",
    "Let's look at the IRIS example again, which has 3 classes. \n",
    "\n",
    "We can create a **Confusion Matrix** that tells us as what classes the flowers were misclassified as.\n",
    "\n",
    "The way to read a confusion matrix is that the rows represent the true labels, and the columns the predicted labels.\n",
    "\n",
    "```\n",
    "['setosa' 'versicolor' 'virginica']\n",
    "array([[15,  0,  0],\n",
    "       [ 0,  8,  3],\n",
    "       [ 0,  5,  7]])\n",
    "```\n",
    "\n",
    "Here, the 15 means that 15 elements belong to the \"setosa\" class (because the value is in the first row), and they were classified as \"setosa\" (because the value is in the first column).\n",
    "\n",
    "Let's look at the 3 in the second row. What does that mean?\n",
    "\n",
    "We know it's in the second row, and the second row represents all elements that belong to the \"versicolor\" class. The 3 is in the third column, the third column represents \"virginica\". This means that 3 elements, that belong to the \"versicolor\" class, were classified wrongly as \"virginica\".\n",
    "\n",
    "Some useful tips: If you sum up a row it tells you how many elements belong to the class in total, and if you sum up the column values then it tells you how many elements were **predicted** as that class.\n",
    "\n",
    "For \"virginica\" we know that 0 + 3 + 7 elements were predicted as it, and that in total 0 + 5 + 7 elements belong to the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbRjOIfQmb37",
    "outputId": "b79c3e63-9466-4f47-86f6-2c01f888775a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(iris.target_names)\n",
    "\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :2], labels[0], random_state=42)\n",
    "X_train.shape\n",
    "\n",
    "y_train = [iris.target_names[x] for x in y_train]\n",
    "y_test = [iris.target_names[x] for x in y_test]\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n_neighbors = 3\n",
    "clf = KNeighborsClassifier(n_neighbors)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "predictions[:10]\n",
    "\n",
    "\n",
    "confusion_matrix(y_test, predictions, labels=iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W3Mb97KYmDiP",
    "outputId": "0ad0f50e-26a0-4c20-a286-24285ee10634"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions, average=\"macro\")\n",
    "recall = recall_score(y_test, predictions, average=\"macro\")\n",
    "f1 = f1_score(y_test, predictions, average=\"macro\")\n",
    "print(accuracy, precision, recall, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSIkSCYJ_aBk"
   },
   "source": [
    "To find the ideal parameters of a classifier we can perform a gridsearch. You specify the parameters, and possible values, and then scikit-learn tries out the combinations for you and tells you which combination has performed the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAHmybCwmQ_t"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    \"C\": [x/10 for x in range(0, 3)],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"max_iter\": [x*1000 for x in range(1, 2)],\n",
    "    \"shuffle\": [False],\n",
    "    \"random_state\": [42],\n",
    "    \"tol\": [0.0001, 0.001, 0.01, 0.1],\n",
    "}\n",
    "clf = PassiveAggressiveClassifier(random_state=42, shuffle=False)\n",
    "clf = GridSearchCV(clf, parameters, cv=5, scoring=\"precision\")\n",
    "\n",
    "# This can take a while!\n",
    "# clf.fit(X_train, train[\"target\"])\n",
    "# print(clf.best_params_)\n",
    "# {'C': 0.2, 'fit_intercept': True, 'max_iter': 1000, 'random_state': 42, 'shuffle': False, 'tol': 0.001}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FCS-HS21 - 18 December 2021",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
