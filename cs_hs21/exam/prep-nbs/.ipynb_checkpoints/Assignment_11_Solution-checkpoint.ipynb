{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSitiJTVbN59"
   },
   "source": [
    "# Assignment 11: Machine Learning\n",
    "\n",
    "Please read the tasks description carefully and implement **only** what the tasks ask you to implement. Closely following the task descriptions will be beneficial, so keep your divergence in check - the test cases below each input cell are the gold standard. Finally, for this assignment, you do not need any error handling, you can assume that all input to your function will be valid.\n",
    "\n",
    "As for the other assignments, using `print` is encouraged to test your implementation but is never required. Make sure not to confuse `return` and `print` statements: If your function has to **return** something, use the `return` statement. \n",
    "\n",
    "Try to implement the tasks yourself or in a small team. If you blindly copy a solution from the Internet or other students, you will not take home any learnings. Rather, make an effort to understand the solution! Furthermore, do not modify the _test cells_ - if you do, you effectively cheat the system which is not helpful for your learning process.\n",
    "\n",
    "Some aspects of this assignment require you to <strong>self-study</strong> and do some research beyond the lecture contents - use your favorite search engine to look up documentation, usage examples, and definitions of the mentioned functions. There might be tasks where you have to read and investigate the [Python Standard Library](https://docs.python.org/3/library/) to find the documentation for a function that is used or that you want to use.\n",
    "\n",
    "This assignment will use the third-party modules  [NumPy](https://numpy.org/https://numpy.org/), [pandas](https://pandas.pydata.org/), [matplotlib](https://matplotlib.org/), and [scikit-learn](https://scikit-learn.org/https://scikit-learn.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll import pandas and matplotlib:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task 1: IRIS-Classification\n",
    "\n",
    "Remember [IRIS](https://archive.ics.uci.edu/ml/datasets/Iris) from last Assignment? Now, we want to classify flowers based on the four available **features**.\n",
    "\n",
    "1. We have to load the data.\n",
    "1. We analyse the data.\n",
    "1. Then, we **must** split the data into a training and testing subset.\n",
    "1. Then, we load and train a classifier.\n",
    "1. Report on the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "\n",
    "iris_features, iris_labels = [sklearn.datasets.load_iris().get(k) for k in ('data', 'target')]\n",
    "\n",
    "iris_label_to_class = {\n",
    "    0: \"setosa\",\n",
    "    1: \"versicolor\",\n",
    "    2: \"virginica\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1.1: Investigate the data\n",
    "\n",
    "In order to know what the data is about, we first have to investigate the data. Visually, this can be done with plots.\n",
    "\n",
    "In the last assigment, we already have drawn a boxplot of the four features for each flower. But what is the distribution of the target labels?\n",
    "\n",
    "Use `matplotlib` (`plt`) to visualize the distribution of the labels of the IRIS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⬇️ Add your code below this line ⬇️\n",
    "\n",
    "# There are many different possible solutions.\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "counts = np.bincount(iris_labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.bar(iris_label_to_class.values(), counts, width=0.5)\n",
    "\n",
    "fig.suptitle(\"Full Distribution of Labels in IRIS\")\n",
    "\n",
    "plt.show()\n",
    "### END SOLUTION\n",
    "# ⬆️ Add your code above this line ⬆️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1.2: The Train-Test-Split\n",
    "\n",
    "For **any** proper machine learning experiment, we **must** split the data into a **mutually exclusive** train and test set.\n",
    "\n",
    "Find a function from the [sklearn documentation](https://duckduckgo.com/?t=ffab&q=sklearn+how+to+train+test+split&ia=web) that splits the IRIS data, given as `iris_features` and `iris_labels` into **70%** for training and **30%** for testing.\n",
    "\n",
    "Call the results accordingly: `X_train`, `y_train`, `X_test`, `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⬇️ Add your code below this line ⬇️\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_features,\n",
    "    iris_labels,\n",
    "    random_state=23, train_size=0.7\n",
    ")\n",
    "\n",
    "### END SOLUTION\n",
    "# ⬆️ Add your code above this line ⬆️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Cell.\n",
    "from unittest import TestCase\n",
    "test_case = TestCase()\n",
    "\n",
    "# Existance\n",
    "test_case.assertTrue('X_train' in locals(), msg='You have to call the train features `X_train`.')\n",
    "test_case.assertTrue('X_test' in locals(), msg='You have to call the test features `X_test`.')\n",
    "test_case.assertTrue('y_train' in locals(), msg='You have to call the train target classes `y_train`.')\n",
    "test_case.assertTrue('y_test' in locals(), msg='You have to call the test target classes `y_test`.')\n",
    "\n",
    "# Datatypes\n",
    "test_case.assertIsInstance(X_train, np.ndarray, msg='Your features (`X_train`) has the wrong datatype.')\n",
    "test_case.assertIsInstance(X_test, np.ndarray, msg='Your features (`X_test`) has the wrong datatype.')\n",
    "test_case.assertIsInstance(y_train, np.ndarray, msg='Your features (`y_train`) has the wrong datatype.')\n",
    "test_case.assertIsInstance(y_test, np.ndarray, msg='Your features (`y_test`) has the wrong datatype.')\n",
    "\n",
    "# Shapes\n",
    "test_case.assertEqual(X_train.shape, (105, 4), msg='The shape of `X_train` is wrong.')\n",
    "test_case.assertEqual(X_test.shape, (45, 4), msg='The shape of `X_test` is wrong.')\n",
    "test_case.assertEqual(y_train.shape, (105,), msg='The shape of `y_train` is wrong.')\n",
    "test_case.assertEqual(y_test.shape, (45,), msg='The shape of `y_test` is wrong.')\n",
    "\n",
    "print(\"\\n\\033[37;42;2m  Success! Your code works as intended.  \\033[0m\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task 1.3: Classification\n",
    "\n",
    "Use the overview from the lecture slides (or [sklearn directory](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)) to select a classifier. (Ignore the first step about the \"< 50 examples\".)\n",
    "Then, use the defined `X_train` and `y_train` to train this classifier.\n",
    "\n",
    "Then, use this classifier and let it classify the test set.\n",
    "Store the result in the variable `y_pred`. (_pred_ is short for predicitions).\n",
    "\n",
    "(There is no test case for this task. Also, there might be a warning about _nonconvergence_. You can ignore that as well. It appears, because there are not enough samples.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⬇️ Add your code below this line ⬇️\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# For this task, there can me multiple solutions.\n",
    "# However, if we follow strictly the referenced map, LinearSVC is the way to go.\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "### END SOLUTION\n",
    "# ⬆️ Add your code above this line ⬆️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task 1.4: Metrics\n",
    "\n",
    "Use the functions, `accuracy_score()`, `precision_recall_fscore_support()`, and `classification_report()` to compute their respective metrics and print them on the console. For Precision, Recall, and F-Score use the _macro_ average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⬇️ Add your code below this line ⬇️\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "report = classification_report(y_test, y_pred, target_names=iris_label_to_class.values())\n",
    "\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F-Score:   {fscore:.4f}\")\n",
    "\n",
    "print(report)\n",
    "\n",
    "### END SOLUTION\n",
    "# ⬆️ Add your code above this line ⬆️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task 2: K-Nearest Neighbors\n",
    "\n",
    "We could use the `KNearestNeighbors` classifier from sklearn but in order to understand the math and mechanics, it is helpful to implement this ourselves.\n",
    "\n",
    "Define the function `k_nearest_neighbors(node, nodes, k=5)` with the three parameters:\n",
    "* `node`: The numerical features for ONE node\n",
    "* `nodes`: A dictionary with the class name as keys and as values, 13-dimensional numpy arrays (the features)\n",
    "* `k=5`: Number of neighbors to determine, defaults to `5`.\n",
    "\n",
    "Return the class name for with the given node is closet throughout all features. Do not use sklearn here but compute it manually with brute-force.\n",
    "\n",
    "For this task, we'll use the [Wine](https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-recognition-dataset) dataset.\n",
    "\n",
    "Use the **euclidean distance** to compute the distance between to points\n",
    "$$\n",
    "    d(p, q) = \\sqrt{ (p_1 - q_1)^2 + (p_2 - q_2)^2 + \\dots + (p_n - q_n)^2}\n",
    "$$\n",
    "\n",
    "\n",
    "Print the `classification_report` for your predictions.\n",
    "It will look like this. Why are your numbers different?\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.86      0.92         7\n",
    "           1       1.00      0.62      0.77         8\n",
    "           2       0.43      1.00      0.60         3\n",
    "\n",
    "    accuracy                           0.78        18\n",
    "   macro avg       0.81      0.83      0.76        18\n",
    "weighted avg       0.90      0.78      0.80        18\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates example data for the wine dataset\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine = pd.DataFrame(sklearn.datasets.load_wine(as_frame=True).frame)\n",
    "wine_train, wine_test = train_test_split(wine, train_size=0.90)\n",
    "\n",
    "wine_X_train = wine_train.to_numpy()[:, :-1]\n",
    "wine_y_train = wine_train.target.to_numpy()\n",
    "wine_X_test = wine_test.to_numpy()[:, :-1]\n",
    "wine_y_test = wine_test.target.to_numpy()\n",
    "\n",
    "TRAIN_NODES = {target: wine_train[wine_train.target == target].to_numpy()[:, :-1] for target in wine_train.target.unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⬇️ Add your code below this line ⬇️\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "def k_nearest_neighbors(node, nodes, k=5):\n",
    "    \n",
    "    # we save the distances as tuples: (distance, class_id)\n",
    "    distances = []\n",
    "    \n",
    "    for class_id, class_features in nodes.items():\n",
    "        for class_feature in class_features:\n",
    "            distances.append((np.sqrt(np.sum((node - class_feature) ** 2)), class_id))\n",
    "\n",
    "    # Now, we sort ASCENDING by the 0th entry (the distance)\n",
    "    distances = sorted(distances, key=lambda d: d[0], reverse=False)\n",
    "    \n",
    "    k_neighbors = [n[1] for n in distances[:k]]\n",
    "\n",
    "    # Select the one that appear the most:\n",
    "    highest_count = max(k_neighbors, key=k_neighbors.count)\n",
    "    \n",
    "    return highest_count\n",
    "\n",
    "### END SOLUTION\n",
    "# ⬆️ Add your code above this line ⬆️\n",
    "\n",
    "wine_y_pred = [\n",
    "    k_nearest_neighbors(sample, TRAIN_NODES)\n",
    "    for sample in wine_X_test\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⬇️ Add your code below this line ⬇️\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(\n",
    "    y_true=wine_y_test,\n",
    "    y_pred=wine_y_pred\n",
    ")    \n",
    "\n",
    "print(report)\n",
    "### END SOLUTION\n",
    "# ⬆️ Add your code above this line ⬆️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2.2: sklearn KNeighbors\n",
    "\n",
    "You just implemented K-Nearest-Neighbors yourself.\n",
    "Now use sklearn's implementation, fit it on the training data and use the test data to predict their class.\n",
    "\n",
    "Like above, print the `classification_report`.\n",
    "\n",
    "The numbers here must be the same as from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⬇️ Add your code below this line ⬇️\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5, algorithm='brute', metric='euclidean')\n",
    "clf.fit(wine_X_train, wine_y_train)\n",
    "wine_y_pred = clf.predict(wine_X_test)\n",
    "\n",
    "report = classification_report(\n",
    "    y_true=wine_y_test,\n",
    "    y_pred=wine_y_pred\n",
    ")    \n",
    "\n",
    "print(report)\n",
    "### END SOLUTION\n",
    "# ⬆️ Add your code above this line ⬆️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_6_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
