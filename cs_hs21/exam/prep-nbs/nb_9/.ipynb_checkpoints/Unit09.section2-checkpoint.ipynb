{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 9\n",
    "# Section 2: Summarization, Aggregation and Grouping of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this section we will look for ways to operate functions on the rows of a DataFrame, as well as to summarise and group the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apply a function to every row in a Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We often want to map across all of the rows in a DataFrame. And Pandas has a function for that: `apply`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's look at an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  United States Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some census data. The data is stored in the file `census.csv` and comes from the *United States Census Bureau*. In particular, this is a breakdown of the population level data at the US county level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('data/census.csv')\n",
    "df = df[df['SUMLEV']==50]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this DataFrame we have five columns for population estimates. Each column corresponds to one year of estimates. It makes sense to create some new columns for minimum or maximum values, and the `apply` function is an easy way to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('data/census.csv')\n",
    "df = df[df['SUMLEV']==50]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First we write a function that \n",
    "* takes a certain row of data, \n",
    "* finds a minimum and maximum value and \n",
    "* returns a new row of data. \n",
    "\n",
    "We call this function `min_max`:\n",
    "* we can create a slice of a row by selecting the population columns \n",
    "* then we use the NumPy `min` and `max` functions and \n",
    "* we create a new series with a label that represents the new values that we want to apply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def min_max(row):\n",
    "    data = row[['POPESTIMATE2010',\n",
    "                'POPESTIMATE2011',\n",
    "                'POPESTIMATE2012',\n",
    "                'POPESTIMATE2013',\n",
    "                'POPESTIMATE2014',\n",
    "                'POPESTIMATE2015']]\n",
    "    return pd.Series({'min': np.min(data), 'max': np.max(data)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then we just need to call `apply` on the DataFrame. <br>\n",
    "Now we have to be careful: We have talked about the zero axis being the rows of the DataFrame. But this parameter here is the parameter of the index (the columns) to be used. So to apply to all rows, pass `axis=1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.apply(min_max, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Please note: `apply` is rarely used in full function definitions, as we have done. Instead, it is usually used in `lambda` functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is a one line example of how to calculate the maximum of columns using the `apply` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rows = ['POPESTIMATE2010',\n",
    "        'POPESTIMATE2011',\n",
    "        'POPESTIMATE2012',\n",
    "        'POPESTIMATE2013',\n",
    "        'POPESTIMATE2014',\n",
    "        'POPESTIMATE2015']\n",
    "df.apply(lambda x: np.max(x[rows]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can imagine how you can chain multiple `apply` calls with `lambda`s to create a readable yet concise data manipulation script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Once the data has been loaded into Python, Pandas makes the calculation of different statistics very simple. For example, `mean`, `max`, `min`, *standard deviations* and more for columns are easily calculable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('data/census.csv')\n",
    "df = df[df['SUMLEV']==50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['CENSUS2010POP'][df['STNAME'] == 'Florida'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['CENSUS2010POP'][df['STNAME'] == 'Florida'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['CENSUS2010POP'][df['STNAME'] == 'Florida'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['CENSUS2010POP'][df['STNAME'] == 'Florida'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The need for custom functions is minimal unless you have very specific requirements. The full range of basic statistics that are quickly calculable and built into the base Pandas package are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| Function | Description                         |\n",
    "|----------|-------------------------------------|\n",
    "| count    | Number of non-null observations     |\n",
    "| sum      | Sum of values                       |\n",
    "| mean     | Mean of values                      |\n",
    "| mad      | Mean absolute deviation             |\n",
    "| median   | Arithmetic median of values         |\n",
    "| min      | Minimum                             |\n",
    "| max      | Maximum                             |\n",
    "| mode     | Mode                                |\n",
    "| abs      | Absolute Value                      |\n",
    "| prod     | Product of values                   |\n",
    "| std      | Unbiased standard deviation         |\n",
    "| var      | Unbiased variance                   |\n",
    "| sem      | Unbiased standard error of the mean |\n",
    "| skew     | Unbiased skewness (3rd moment)      |\n",
    "| kurt     | Unbiased kurtosis (4th moment)      |\n",
    "| quantile | Sample quantile (value at %)        |\n",
    "| cumsum   | Cumulative sum                      |\n",
    "| cumprod  | Cumulative product                  |\n",
    "| cummax   | Cumulative maximum                  |\n",
    "| cummin   | Cumulative minimum                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `describe()` function is a useful summary tool that quickly displays statistics for each variable or group to which it is applied. The output of `describe()` varies depending on whether you apply it to a numeric or character column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['CENSUS2010POP'][df['STNAME'] == 'Florida'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "For numeric data, the result’s index will include count, mean, std, min, max as well as lower, 50 and upper percentiles. By default the lower percentile is 25 and the upper percentile is 75. The 50 percentile is the same as the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('data/census.csv')\n",
    "df = df[df['SUMLEV']==50]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By mastering the `groupby()` functionality of the Pandas, power is placed in your hands. Groupby divides the data into groups, depending on a variable of your choice. For example, the expression `data.groupby('STNAME')` divides our current DataFrame into state names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The function `groupby()` returns a GroupBy object, but essentially describes how the rows of the original data set were split. The GroupBy object `.groups` variable is a dictionary whose keys are the computed unique groups and the corresponding values are the `axis` labels that belong to each group. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('STNAME').groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "len(df.groupby(['STNAME']).groups['Florida'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The group \"Florida\" consists of **67** entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Functions like `max()`, `min()`, `mean()`, `first()`, `last()` can be quickly applied to the GroupBy object to obtain summary statistics for each group – an immensely useful function. Different variables can be excluded / included from each summary requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Get the first entry for each state with `first()`. <br>\n",
    "*Please note: to have a clear overview, we only show the first five entries via 'head()' here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "firstdf = df.groupby('STNAME').first()\n",
    "firstdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What is the average population of a county per state, based on the 2010 census?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('STNAME')['CENSUS2010POP'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `groupby` output will have an index or multi-index on rows corresponding to your chosen grouping variables. To avoid setting this index, pass `as_index=False` to the groupby operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['SUMLEV']==50]\n",
    "df.groupby('STNAME', as_index=False)['CENSUS2010POP'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We have already seen how we can select a group using the `groups` dictionary and the corresponding key. Another way to select a group is to use `GroupBy.get_group()`.  This function returns a DataFrame containing the data of the given group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the following example we get the DataFrame of the `Florida` group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('STNAME').get_group('Florida')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Applying specific functions to various columns in groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Please note that `agg` and `aggregate` can be used interchangeably. `agg` is shorter, so let's use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions for aggregation are provided in the form of a python dictionary or list. The dictionary keys are used to specify the columns on which you want to perform operations and the dictionary values to specify the function to be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('STNAME').agg({'CENSUS2010POP': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['SUMLEV']==50]\n",
    "df.groupby('STNAME').agg(\n",
    "        {\n",
    "            'CENSUS2010POP': 'mean',\n",
    "            'CTYNAME': 'count'\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The aggregation dictionary syntax is flexible and can be defined before the operation. You can also define functions inline using `lambda` functions to extract statistics that are not provided by the built-in options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define the aggregation procedure outside of the groupby operation\n",
    "aggregations = {\n",
    "    'CTYNAME': 'sum', # or try lambda here too: lambda names: '; '.join(names)\n",
    "    'CENSUS2010POP': lambda x: sum(x)/1_000_000 # population total per 1 million inhabitants\n",
    "}\n",
    "df.groupby('STNAME').agg(aggregations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Applying multiple functions to columns in groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply multiple functions to a single column in your grouped data, expand the syntax above to pass in a list of functions as the value in your aggregation dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['SUMLEV']==50]\n",
    "df.groupby('STNAME').agg(\n",
    "        {\n",
    "            'CENSUS2010POP':  ['min', 'max', 'sum'],\n",
    "            'CTYNAME':  ['min', 'max', 'count'],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `agg()` syntax is flexible and easy to use. Remember that you can pass custom and lambda functions to your list of aggregated calculations, and each will be passed the values from the column in your grouped data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Renaming grouped aggregation columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas supports group aggregation with relabelling by **named aggregation** with simple tuples. Python tuples are used to provide the column name to work on along with the function to **apply**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['SUMLEV']==50]\n",
    "df.groupby('STNAME').agg(\n",
    "        # get min of the population for each group\n",
    "        pop_min= ('CENSUS2010POP', min),\n",
    "        # get max of the population for each group\n",
    "        pop_max= ('CENSUS2010POP', max),\n",
    "        # get sum of the population for each group\n",
    "        pop_sum= ('CENSUS2010POP', sum),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The GroupBy functionality in Pandas is performant and is well documented in the official [docs](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
